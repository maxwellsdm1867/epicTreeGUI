---
phase: 05-datajoint-integration-export-mat-from-datajoint-query-results
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - python/__init__.py
  - python/export_mat.py
  - python/field_mapper.py
  - python/tests/__init__.py
  - python/tests/test_export.py
  - python/requirements.txt
autonomous: true

must_haves:
  truths:
    - "export_to_mat() accepts generate_tree(include_meta=True) output and produces a valid .mat file"
    - "MATLAB loadEpicTreeData() can load the exported .mat file without errors"
    - "Exported .mat structure matches DATA_FORMAT_SPECIFICATION: format_version, metadata, experiments hierarchy"
    - "Animal and Preparation metadata are flattened into cell-level properties"
    - "JSON parameter blobs are flattened to single-level MATLAB structs"
    - "Response structs contain h5_path for lazy loading, not embedded waveform data"
    - "MEA experiments raise ValueError with descriptive error message"
    - "None/null values are sanitized to MATLAB-compatible empty arrays or strings"
  artifacts:
    - path: "python/export_mat.py"
      provides: "Main export function converting DataJoint tree to .mat format"
      contains: "def export_to_mat"
    - path: "python/field_mapper.py"
      provides: "DataJoint-to-epicTree field mapping and JSON extraction"
      contains: "def flatten_json_params"
    - path: "python/tests/test_export.py"
      provides: "Unit tests for export module"
      contains: "def test_"
  key_links:
    - from: "python/export_mat.py"
      to: "python/field_mapper.py"
      via: "import"
      pattern: "from.*field_mapper import"
    - from: "python/export_mat.py"
      to: "scipy.io.savemat"
      via: "function call"
      pattern: "scipy\\.io\\.savemat"
---

<objective>
Build the Python export module that converts DataJoint `generate_tree(include_meta=True)` output into epicTreeGUI's standard .mat format using scipy.io.savemat().

Purpose: This is the core data transformation layer â€” all other Phase 05 deliverables depend on this module producing correct .mat files that MATLAB can load.

Output: Working, tested Python package in `epicTreeGUI/python/` with export_mat.py, field_mapper.py, and unit tests.
</objective>

<execution_context>
@/Users/maxwellsdm/.claude/get-shit-done/workflows/execute-plan.md
@/Users/maxwellsdm/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@docs/dev/DATA_FORMAT_SPECIFICATION.md
@src/loadEpicTreeData.m
@.planning/phases/05-datajoint-integration-export-mat-from-datajoint-query-results/05-RESEARCH.md
</context>

<feature>
  <name>DataJoint-to-epicTreeGUI .mat Export</name>
  <files>
    python/export_mat.py
    python/field_mapper.py
    python/tests/test_export.py
    python/requirements.txt
    python/__init__.py
    python/tests/__init__.py
  </files>
  <behavior>
    The export module transforms DataJoint's `generate_tree(include_meta=True)` output (9-level hierarchy) into epicTreeGUI's 5-level .mat format.

    **Input structure** (from generate_tree in datajoint/next-app/api/helpers/query.py):
    ```python
    [
      {
        'level': 'experiment', 'id': 1, 'is_mea': False,
        'label': '...', 'object': [{ full DB row }], 'tags': [...],
        'children': [
          { 'level': 'animal', 'id': 5, 'object': [{ ... species, age, ... }],
            'children': [
              { 'level': 'preparation', 'object': [{ ... bath_solution, region, ... }],
                'children': [
                  { 'level': 'cell', 'object': [{ type, properties, ... }],
                    'children': [
                      { 'level': 'epoch_group', ... children: [
                        { 'level': 'epoch_block', ... children: [
                          { 'level': 'epoch', 'responses': [...], 'stimuli': [...] }
                        ]}
                      ]}
                    ]
                  }
                ]
              }
            ]
          }
        ]
      }
    ]
    ```

    **Output structure** (must match DATA_FORMAT_SPECIFICATION exactly):
    ```python
    {
      'format_version': '1.0',
      'metadata': { 'created_date': '...', 'data_source': 'DataJoint + H5 files', 'export_user': '...' },
      'experiments': [
        {
          'id': 1, 'exp_name': '20250115A', 'is_mea': False, 'label': '...',
          'start_time': '...', 'experimenter': '...', 'rig': '...', 'institution': '...',
          'cells': [
            {
              'id': 42, 'label': '...', 'type': 'OnP',
              'properties': { 'species': '...', 'bath_solution': '...', 'region': '...' },
              'noise_id': 0, 'rf_params': {},
              'epoch_groups': [
                {
                  'id': ..., 'label': '...', 'protocol_name': '...', 'protocol_id': ...,
                  'start_time': '...', 'end_time': '...',
                  'epoch_blocks': [
                    {
                      'id': ..., 'label': '...', 'protocol_name': '...', 'protocol_id': ...,
                      'start_time': '...', 'end_time': '...', 'parameters': { flat struct },
                      'epochs': [
                        {
                          'id': ..., 'label': '...', 'start_time': '...', 'end_time': '...',
                          'parameters': { flat struct },
                          'responses': [
                            { 'device_name': 'Amp1', 'data': [], 'h5_path': '...', 'h5_file': '...',
                              'sample_rate': 10000, 'sample_rate_units': 'Hz', 'units': 'mV',
                              'spike_times': [], 'offset_ms': 0.0 }
                          ],
                          'stimuli': [
                            { 'device_name': 'Stage', 'data': [], 'h5_path': '...', 'h5_file': '...',
                              'sample_rate': 10000, 'units': 'normalized' }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          ]
        }
      ]
    }
    ```

    **Key transformations:**
    - Animal/Preparation metadata merged into cell `properties` dict
    - JSON `parameters` blobs flattened to single-level dicts (nested keys become underscore-separated: `stimulus.spot.intensity` -> `stimulus_spot_intensity`)
    - None values sanitized to `[]` (arrays) or `''` (strings)
    - `is_mea=True` experiments raise ValueError (single-cell only per user constraint)
    - Response/Stimulus structs preserve h5_path + h5_file for lazy loading, `data` field is empty array
    - `sample_rate` parsed from string (e.g., "10000 Hz") to numeric float
    - Tags exported as `tags` field on each level (list of {user, tag} dicts)
    - H5 file path fetched from experiment-level `data_file` field in `object` dict

    **Test cases:**
    - Single experiment with 1 cell, 1 epoch group, 1 block, 2 epochs -> valid .mat file
    - Multiple experiments -> all serialized correctly
    - MEA experiment (is_mea=True) -> raises ValueError
    - Missing optional fields (label=None, experimenter=None) -> empty strings in output
    - Nested JSON parameters -> flattened to single level
    - Empty responses/stimuli arrays -> empty MATLAB cell arrays
    - Round-trip: export .mat -> load in scipy.io.loadmat -> verify structure matches
    - H5 path preservation: response.h5_path and response.h5_file populated from DataJoint fields
  </behavior>
  <implementation>
    **field_mapper.py:**
    - `sanitize_for_matlab(value)`: Convert None -> [], empty dict -> {}, etc.
    - `flatten_json_params(params_dict, prefix='')`: Recursively flatten nested dicts with underscore separators
    - `parse_sample_rate(rate_str)`: Convert "10000 Hz" or "10 kHz" to numeric float
    - `extract_experiment_fields(obj_dict)`: Extract known experiment fields from DB row
    - `extract_animal_fields(obj_dict)`: Extract known animal metadata fields
    - `extract_preparation_fields(obj_dict)`: Extract known preparation metadata fields
    - `extract_cell_fields(obj_dict)`: Extract known cell fields
    - `extract_epoch_group_fields(obj_dict)`: Extract known epoch_group fields
    - `extract_epoch_block_fields(obj_dict)`: Extract known epoch_block fields
    - `extract_epoch_fields(obj_dict)`: Extract known epoch fields
    - `build_response_struct(resp_dict, h5_file)`: Build response struct with h5_path lazy loading
    - `build_stimulus_struct(stim_dict, h5_file)`: Build stimulus struct with h5_path

    **export_mat.py:**
    - `export_to_mat(tree_data, username, download_dir, h5_file_path=None)`: Main entry point
    - `build_experiment(exp_node)`: Process experiment node, check is_mea, extract fields
    - `build_cell(cell_node, animal_meta, prep_meta)`: Build cell with merged Animal/Prep metadata
    - `build_epoch_group(eg_node, h5_file)`: Build epoch group
    - `build_epoch_block(eb_node, h5_file)`: Build epoch block with flattened parameters
    - `build_epoch(epoch_node, h5_file)`: Build epoch with responses/stimuli
    - Internal: traverse Experiment -> Animal -> Preparation -> Cell, flattening the first two into cell properties

    **scipy.io.savemat options:**
    - `do_compression=True` (per discretion: reduce file size)
    - `oned_as='row'` (MATLAB convention)
    - `format='5'` (most compatible MATLAB format)

    **requirements.txt:**
    - scipy>=1.14
    - numpy>=1.24
    - h5py>=3.9
  </implementation>
</feature>

<verification>
- `cd python && python -m pytest tests/test_export.py -v` passes all tests
- Exported .mat file loads in scipy.io.loadmat without errors
- Exported structure has format_version='1.0', metadata dict, experiments list
- Each experiment has cells (not animals/preparations at top level)
- Cell properties contain merged animal/preparation metadata
- Response structs have h5_path field, empty data field
- MEA input raises ValueError
</verification>

<success_criteria>
- All unit tests pass
- Export function produces .mat files loadable by MATLAB loadEpicTreeData()
- Animal/Preparation flattening works correctly
- JSON parameter flattening produces single-level dicts
- Null/None handling produces MATLAB-compatible values
</success_criteria>

<output>
After completion, create `.planning/phases/05-datajoint-integration-export-mat-from-datajoint-query-results/05-01-SUMMARY.md`
</output>
